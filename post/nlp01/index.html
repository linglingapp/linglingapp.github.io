<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>自然言語処理のためのライブラリ - Japanese &amp; Korean</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Mincheol" /><meta name="description" content="TensorFlow 2015年に公開された，Googleのマシンラーニングライブラリ。使いやすいので，Pythonで簡単にモデリングやテストができる。Tens" /><meta name="keywords" content="Japanese, Korean" />






<meta name="generator" content="Hugo 0.75.1 with theme even" />


<link rel="canonical" href="https://linglingapp.github.io/post/nlp01/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.c7bc1becf36bcf6a9ebd25d2947e43a2eb745ddb0c9a32b43126fd7fa460c351.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="自然言語処理のためのライブラリ" />
<meta property="og:description" content="TensorFlow 2015年に公開された，Googleのマシンラーニングライブラリ。使いやすいので，Pythonで簡単にモデリングやテストができる。Tens" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://linglingapp.github.io/post/nlp01/" />
<meta property="article:published_time" content="2020-10-21T01:37:56+08:00" />
<meta property="article:modified_time" content="2020-10-21T01:37:56+08:00" />
<meta itemprop="name" content="自然言語処理のためのライブラリ">
<meta itemprop="description" content="TensorFlow 2015年に公開された，Googleのマシンラーニングライブラリ。使いやすいので，Pythonで簡単にモデリングやテストができる。Tens">
<meta itemprop="datePublished" content="2020-10-21T01:37:56+08:00" />
<meta itemprop="dateModified" content="2020-10-21T01:37:56+08:00" />
<meta itemprop="wordCount" content="3563">



<meta itemprop="keywords" content="NLP," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="自然言語処理のためのライブラリ"/>
<meta name="twitter:description" content="TensorFlow 2015年に公開された，Googleのマシンラーニングライブラリ。使いやすいので，Pythonで簡単にモデリングやテストができる。Tens"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Japanese &amp; Korean</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Japanese &amp; Korean</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">自然言語処理のためのライブラリ</h1>

      <div class="post-meta">
        <span class="post-time"> 2020年10月21日 </span>
        <div class="post-category">
            <a href="/categories/%E6%97%A5%E6%9C%AC%E8%AA%9E/"> 日本語 </a>
            </div>
          <span class="more-meta"> 3563 文字 </span>
          <span class="more-meta"> 読了時間: 8 分 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">CONTENTS</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#tensorflow">TensorFlow</a>
      <ul>
        <li><a href="#tfkeraslayers">tf.keras.layers</a>
          <ul>
            <li><a href="#tfkeraslayersdense">tf.keras.layers.Dense</a></li>
            <li><a href="#tfkeraslayersdropout">tf.keras.layers.Dropout</a></li>
            <li><a href="#tfkeraslayersconv1d">tf.keras.layers.Conv1D</a></li>
            <li><a href="#tfkeraslayersmaxpool1d">tf.keras.layers.MaxPool1D</a></li>
          </ul>
        </li>
        <li><a href="#tensorflow-20">TensorFlow 2.0</a>
          <ul>
            <li><a href="#モデルの構築">モデルの構築</a></li>
            <li><a href="#sequential-api">Sequential API</a></li>
            <li><a href="#functional-api">Functional API</a></li>
            <li><a href="#custom-layers">Custom Layers</a></li>
            <li><a href="#subclassing-custom-model">Subclassing (Custom Model)</a></li>
            <li><a href="#モデルの学習">モデルの学習</a></li>
            <li><a href="#内部apiの活用">内部APIの活用</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#scikit-learn">scikit-learn</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <h1 id="tensorflow">TensorFlow</h1>
<p>2015年に公開された，Googleのマシンラーニングライブラリ。使いやすいので，Pythonで簡単にモデリングやテストができる。TensorFlowのTensorは「N次元のマトリックス」を意味する。つまり，TensorをFlowするということは，データの流動グラフ（Data flow graph）を利用して数値演算する過程を意味する。</p>
<h2 id="tfkeraslayers">tf.keras.layers</h2>
<p>TensorFlowのkerasモジュールの一つで，ディープラーニング・オープンソース。</p>
<h3 id="tfkeraslayersdense">tf.keras.layers.Dense</h3>
<p>Denseは，ニューラルネットワークの最も基本的な形態を意味する。この関数は，以下の式を満たす基本的なニューラルネットワークの層を作る。</p>
<p>$$ y=f(Wx+b) $$</p>
<p><em>x</em>と<em>b</em>は，それぞれ入力ベクトル，バイアスベクトルである。<em>W</em>は重み行列。つまり，重み行列に入力ベクトルをかけて，バイアスベクトルを加え，その値に<em>f</em>という関数を適用する構造である。</p>
<p>kerasのDenseを使用するには，まずオブジェクトを作る必要がある。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>ここに入力値を与える。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># オブジェクトを作った後に与える</span>
<span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">dense</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># オブジェクトを作るときに設定</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span> <span class="o">...</span> <span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>オブジェクトを作るときに与えることができる引数は次の通り。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="fm">__init__</span><span class="p">(</span>
	<span class="n">units</span><span class="p">,</span>
	<span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
	<span class="n">bias_initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
	<span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">bias_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">kernel_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">bias_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>たとえば，入力値に対してシグモイド関数を使用し，出力として10個の値を出す完全連結階層（Fully Connected Layer）は，次のように書ける。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>10個のノードを持つ隠れ層があり，最終的な出力は2個のニューラルネットワーク構造は，次のようにオブジェクトを二つ作ればよい。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span><span class="p">)</span>
<span class="n">hidden</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)(</span><span class="n">hidden</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="tfkeraslayersdropout">tf.keras.layers.Dropout</h3>
<p>このモジュールは，<code>keras.layers</code>に入力される値に対し，ドロップアウトを適用する。ニューラルネットワークを作るときの問題点として，Overfittingがある。この問題は，正規化（Regularization）をすることで解決される。ドロップアウト（dropout）は，代表的な正規化方法の一つである。使い方は，先ほどのdense層を作る方法と似ている。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>ドロップアウトの適用には，入力値が必要。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># オブジェクトを作った後，再び呼び出して入力値を設定する方法</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># オブジェクトを作るときに入力値を設定する方法</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span> <span class="o">...</span> <span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>ドロップアウトの引数としては，次のようなものがある。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="fm">__init__</span><span class="p">(</span>
	<span class="n">rate</span><span class="p">,</span>
	<span class="n">noise_shape</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">seed</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>ドロップアウトを適用する例。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span><span class="p">)</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>先ほどのdenseにおいて取り上げたニューラルネットワーク構造で，最初の入力値にドロップアウトを適用すると…</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span><span class="p">)</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">hidden</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)(</span><span class="n">dropout</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">)(</span><span class="n">hidden</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="tfkeraslayersconv1d">tf.keras.layers.Conv1D</h3>
<p>コンボリューション（Convolution）。TensorFlowのコンボリューションは，Conv1D・Conv2D・Conv3Dに分かれる。一般的にコンボリューションは二つを基準を用いて区別することができる。①コンボリューションが進む方向，②出力される値である。</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">コンボリューションの方向</th>
<th style="text-align:center">出力値</th>
</tr>
</thead>
<tbody>
<tr>
<td>Conv1D</td>
<td style="text-align:center">一方向（横）</td>
<td style="text-align:center">1-D Array(vector)</td>
</tr>
<tr>
<td>Conv2D</td>
<td style="text-align:center">二方向（横・縦）</td>
<td style="text-align:center">2-D Array(matrix)</td>
</tr>
<tr>
<td>Conv3D</td>
<td style="text-align:center">三方向（横・縦・高さ）</td>
<td style="text-align:center">3-D Array(tensor)</td>
</tr>
</tbody>
</table>
<p>Conv1Dも，DenseやDropoutの使用方法とほとんど同じ。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># オブジェクトを作った後，再び呼び出して入力値を設定する方法</span>
<span class="n">conv1d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">conv1d</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># オブジェクトを作るときに入力値を設定する方法</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span> <span class="o">...</span> <span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>オブジェクトを作る際に渡すことができる引数は以下の通り。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="fm">__init__</span><span class="p">(</span>
	<span class="n">filters</span><span class="p">,</span>
	<span class="n">kernel_size</span><span class="p">,</span>
	<span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
	<span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span>
	<span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;channels_last&#39;</span><span class="p">,</span>
	<span class="n">dilation_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
	<span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">use_bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
	<span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
	<span class="n">bias_initializer</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
	<span class="n">kernel_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">bias_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">activity_regularizer</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">kernel_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">bias_constraint</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="o">**</span><span class="n">kwargs</span>	
<span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>たとえば，(5, 10)の値に対して，フィルターの大きさ<code>kernel_size</code>を2にし，個数を10個に指定する場合，出力される値は(1,4,10)になる。</p>
<p>Conv1Dを利用したコンボリューション・ニューラルネットワークは，次のようにして作ることができる。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span><span class="p">)</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span>
	<span class="n">filters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
	<span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
	<span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
	<span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>入力値にドロップアウトを適用したコンボリューション・ニューラルネットワークも可能。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span><span class="p">)</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span>
	<span class="n">filters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
	<span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
	<span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
	<span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="tfkeraslayersmaxpool1d">tf.keras.layers.MaxPool1D</h3>
<p>プールは，コンボリューション・ニューラルネットワークといっしょに使われる技法の一つ。一般的には，feature mapの大きさを減らしたり，主要な特徴を抜き出すため，コンボリューションの後に適用される。</p>
<p>プールには二つの技法がある。一つは，max-poolingで，もう一つはaverage-poolingである。前者はfeature mapに対し，最大値だけを抜き出し，後者は平均値を抜き出す方法である。</p>
<p>max-poolingもコンボリューションのように，MaxPool1D，MaxPool2D，MaxPool3Dの三つのモデルに分けられる。原理もコンボリューションと同じ。自然言語処理ではMaxPool1Dがよく用いられる。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># オブジェクトを作った後，再び呼び出して入力値を設定する方法</span>
<span class="n">max_pool</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool1D</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>
<span class="n">max_pool</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="c1"># オブジェクトを作るときに入力値を設定する方法</span>
<span class="n">max_pool</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool1D</span><span class="p">(</span> <span class="o">...</span> <span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>以下は，引数リスト。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="fm">__init__</span><span class="p">(</span>
	<span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
	<span class="n">strides</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="n">padding</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span>
	<span class="n">data_format</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span>
	<span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>入力値が，コンボリューションとmax poolingを使用した後，完全連結階層を通じて最終出力値が出る構造を作ってみる。そして，入力値にはドロップアウトを適用。max poolingの結果を階層につなげるためには，行列をベクトルにしなければならないので，<code>tf.keras.layers.Flatten</code>を使用する。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">INPUT_SIZE</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">INPUT_SIZE</span><span class="p">)</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">conv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span>
	<span class="n">filters</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
	<span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
	<span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span>
	<span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">max_pool</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">MaxPool1D</span><span class="p">(</span><span class="n">pool_size</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="s1">&#39;same&#39;</span><span class="p">)(</span><span class="n">conv</span><span class="p">)</span>
<span class="n">flatten</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()(</span><span class="n">max_pool</span><span class="p">)</span>
<span class="n">hidden</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)(</span><span class="n">flatten</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)(</span><span class="n">hidden</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="tensorflow-20">TensorFlow 2.0</h2>
<p>TensorFlow 2.0では，散らかっていた既存のAPIを統合・削除し，また，pythonで活用できるようにEager executionの統合を行った。</p>
<h3 id="モデルの構築">モデルの構築</h3>
<p>TensorFlow 2.0では，kerasを利用してモデルを構築することを推奨している。keras APIは高水準（High-level）APIで，使いやすく，とても柔軟な性能を見せてくれる。kerasを利用したモデルの構築方法は，次のように分けることができる。</p>
<ul>
<li>Sequential API</li>
<li>Functional API</li>
<li>Functional/Sequential API
<ul>
<li>Custom Layers</li>
</ul>
</li>
<li>Subclassing (Custom Model)</li>
</ul>
<h3 id="sequential-api">Sequential API</h3>
<p><code>tf.keras.Sequential</code>は，kerasを活用してモデルを構築できる最も簡単な形態のAPIである。これを利用すると，簡単な層の積み重ねが実現できる。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</code></pre></td></tr></table>
</div>
</div><p>このように，Sequentialモジュールはとても簡単な仕組みである。したがって，以下のようにモデルの層の積み重ねが複雑な場合，このモジュールは不向きである。</p>
<ul>
<li>Multi-input models</li>
<li>Multi-output models</li>
<li>Models with shared layers</li>
<li>Models with non-sequential data flows</li>
</ul>
<p>上記のようなモデルを実現させるためには，kerasのFunctional APIやSubclassingを利用する。</p>
<h3 id="functional-api">Functional API</h3>
<p>先ほどSequential APIで構築したモデルと同じものをFunctional APIで作ってみる。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>Functional APIでは，入力値を受けるInputモジュールの宣言が必要である。その際には，形態（shape）を定義する必要がある。</p>
<h3 id="custom-layers">Custom Layers</h3>
<p>今までは，dense層が複数回使われたニューラルネットワークを利用した。このニューラルネットワークを一つの層にまとめて再利用性を向上させるのであれば，次のようにカスタム層として定義しておけばよい。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">CustomLayer</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>

	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_dimension</span><span class="p">,</span> <span class="n">hidden_dimension2</span><span class="p">,</span> <span class="n">output_dimension</span><span class="p">):</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">hidden_dimension</span> <span class="o">=</span> <span class="n">hidden_dimension</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">hidden_dimension2</span> <span class="o">=</span> <span class="n">hidden_dimension2</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">output_dimension</span> <span class="o">=</span> <span class="n">output_dimension</span>
		<span class="nb">super</span><span class="p">(</span><span class="n">CustomLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
		
	<span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">dense_layer1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dimension</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">dense_layer2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dimension2</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">dense_layer3</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_dimension</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
		
	<span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layer1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		
		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layer3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p>カスタム層を定義する際には，layersパッケージのLayerクラスを引継ぎ，上記のように三つのメソッドを定義すればよい。</p>
<p>このように定義したものは，Sequential APIやFunctional APIを活用するときに用いることができる。以下は，Sequentialモジュールを活用する場合の例である。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">CustomLayer</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="subclassing-custom-model">Subclassing (Custom Model)</h3>
<p>自由度の高いSubclassingは，カスタム層を作る方法と似ている。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">MyModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_dimension</span><span class="p">,</span> <span class="n">hidden_dimension2</span><span class="p">,</span> <span class="n">output_dimension</span><span class="p">):</span>
		<span class="nb">super</span><span class="p">(</span><span class="n">MyModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;my model&#39;</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">dense_layer1</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dimension</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">dense_layer2</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dimension2</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">)</span>
		<span class="bp">self</span><span class="o">.</span><span class="n">dense_layer3</span> <span class="o">=</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">output_dimension</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
		
	<span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layer1</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
		<span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layer2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
		
		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layer3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="モデルの学習">モデルの学習</h3>
<p>モデルの学習とは言え，ここには検証や予測など，その他のプロセスも含まれる。モデルの学習方法は，大きく分けて二つある。</p>
<ul>
<li>kerasモデルの内部APIを活用する(e.g. model.fit(), model.evaluate(), model.predict())</li>
<li>学習・検証・予測など，すべてのプロセスをGradientTapeオブジェクトを活用して直接実現させる</li>
</ul>
<p>以下では前者の方法を用いる。</p>
<h3 id="内部apiの活用">内部APIの活用</h3>
<h1 id="scikit-learn">scikit-learn</h1>
<p>Python用のマシンラーニング・ライブラリ。Pythonでマシンラーニング・モデルを作るのに最適のライブラリである。</p>

    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/nlp/">NLP</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/repetition-reduplication/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">중복과 반복, 그리고 중복과 반복</span>
            <span class="prev-text nav-mobile">前の記事へ</span>
          </a>
        <a class="next" href="/post/latex/">
            <span class="next-text nav-default">LaTeXのインストールに関する覚え書き</span>
            <span class="next-text nav-mobile">次の記事へ</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="disqus_thread"></div>
    <script type="text/javascript">
    (function() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'https-linglingapp-github-io';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://linglingapp.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2020<span class="heart"><i class="iconfont icon-heart"></i></span><span>Mincheol</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.c12618f9a600c40bd024996677e951e64d3487006775aeb22e200c990006c5c7.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        }
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js" integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin="anonymous"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-G-YEYS2GL3GY', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
